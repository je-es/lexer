{"version":3,"sources":["../lib/core.ts","../lib/lexer.ts"],"sourcesContent":["// core.ts\n//\n// Developed with ❤️ by Maysara.\n\n\n\n// ╔════════════════════════════════════════ TYPES ═══════════════════════════════════════╗\n\n    export interface Token {\n        type: string;\n        value: string;\n        offset: number;\n        line: number;\n        col: number;\n    }\n\n    export interface RuleConfig {\n        match: RegExp;\n        value?: (text: string) => string;\n        lineBreaks?: boolean;\n    }\n\n    export type Rule = string | RegExp | string[] | RuleConfig;\n\n    export interface Rules {\n        [key: string]: Rule;\n    }\n\n// ╚══════════════════════════════════════════════════════════════════════════════════════╝\n\n\n\n// ╔════════════════════════════════════════ CORE ════════════════════════════════════════╗\n\n    export class Lexer {\n        private fastRegex       : RegExp | null                         = null;\n        private ruleTypes       : string[]                              = [];\n        private ruleTransforms  : (((text: string) => string) | null)[] = [];\n        private ruleLineBreaks  : boolean[]                             = [];\n        private buffer          : string                                = '';\n        private position        : number                                = 0;\n        private line            : number                                = 1;\n        private col             : number                                = 1;\n        private length          : number                                = 0;\n\n        constructor(rules: Rules) {\n            this.compileRules(rules);\n        }\n\n        private compileRules(rules: Rules): void {\n            const patterns      : string[]                              = [];\n            const types         : string[]                              = [];\n            const transforms    : (((text: string) => string) | null)[] = [];\n            const lineBreaks    : boolean[]                             = [];\n\n            for (const [name, rule] of Object.entries(rules)) {\n                let pattern         : string;\n                let transform       : ((text: string) => string) | null = null;\n                let hasLineBreaks   : boolean                           = false;\n\n                if (typeof rule === 'symbol' && rule === error) {\n                    // Skip error rule for now - handle in fallback\n                    continue;\n                } else if (typeof rule === 'string') {\n                    pattern = this.escapeRegex(rule);\n                } else if (rule instanceof RegExp) {\n                    pattern = rule.source;\n                } else if (Array.isArray(rule)) {\n                    // Keywords with word boundaries - optimize common case\n                    if (rule.length === 1) {\n                        pattern = `${this.escapeRegex(rule[0])}(?![a-zA-Z0-9_])`;\n                    } else {\n                        pattern = `(?:${rule.map(k => this.escapeRegex(k)).join('|')})(?![a-zA-Z0-9_])`;\n                    }\n                } else {\n                    // RuleConfig\n                    const config = rule as RuleConfig;\n                    pattern = config.match.source;\n                    transform = config.value || null;\n                    hasLineBreaks = config.lineBreaks || false;\n                }\n\n                patterns.push(`(${pattern})`);\n                types.push(name);\n                transforms.push(transform);\n                lineBreaks.push(hasLineBreaks);\n            }\n\n            // Compile single mega-regex for maximum performance\n            if (patterns.length > 0) {\n                this.fastRegex = new RegExp(patterns.join('|'), 'gy');\n            }\n\n            // Store as flat arrays for better cache performance\n            this.ruleTypes = types;\n            this.ruleTransforms = transforms;\n            this.ruleLineBreaks = lineBreaks;\n        }\n\n        private escapeRegex(str: string): string {\n            return str.replace(/[.*+?^${}()|[\\]\\\\]/g, '\\\\$&');\n        }\n\n        reset(input: string): void {\n            this.buffer = input;\n            this.length = input.length;\n            this.position = 0;\n            this.line = 1;\n            this.col = 1;\n\n            if (this.fastRegex) {\n                this.fastRegex.lastIndex = 0;\n            }\n        }\n\n        next(): Token | undefined {\n            // Early exit for end of input\n            if (this.position >= this.length) {\n                return undefined;\n            }\n\n            if (this.fastRegex) {\n                this.fastRegex.lastIndex = this.position;\n                const match = this.fastRegex.exec(this.buffer);\n\n                if (match && match.index === this.position) {\n                    // Find which group matched - optimized loop\n                    let ruleIndex = 0;\n                    let text = '';\n\n                    // Start from index 1 (skip full match)\n                    for (let i = 1; i < match.length; i++) {\n                        if (match[i] !== undefined) {\n                            ruleIndex = i - 1;\n                            text = match[i];\n                            break;\n                        }\n                    }\n\n                    const startLine = this.line;\n                    const startCol = this.col;\n                    const startPos = this.position;\n                    const textLength = text.length;\n\n                    // Update position\n                    this.position += textLength;\n\n                    // Optimized line/col tracking\n                    if (this.ruleLineBreaks[ruleIndex]) {\n                        // Fast newline counting\n                        for (let i = 0; i < textLength; i++) {\n                            if (text.charCodeAt(i) === 10) { // '\\n'\n                                this.line++;\n                                this.col = 1;\n                            } else {\n                                this.col++;\n                            }\n                        }\n                    } else {\n                        this.col += textLength;\n                    }\n\n                    // Apply transformation if exists\n                    const transform = this.ruleTransforms[ruleIndex];\n                    const value = transform ? transform(text) : text;\n\n                    return {\n                        type        : this.ruleTypes[ruleIndex],\n                        value,\n                        offset      : startPos,\n                        line        : startLine,\n                        col         : startCol\n                    };\n                }\n            }\n\n            // Fallback: error token\n            const char = this.buffer[this.position];\n            const token = {\n                type        : 'error',\n                value       : char,\n                offset      : this.position,\n                line        : this.line,\n                col         : this.col\n            };\n\n            this.position++;\n            this.col++;\n\n            return token;\n        }\n\n        *[Symbol.iterator](): Iterator<Token> {\n            let token: Token | undefined;\n            while ((token = this.next()) !== undefined) {\n                yield token;\n            }\n        }\n    }\n\n    export const error = Symbol('error');\n\n    export function compile(rules: Rules): Lexer {\n        return new Lexer(rules);\n    }\n\n    export default { compile, error };\n\n// ╚══════════════════════════════════════════════════════════════════════════════════════╝","// lexer.ts — A lightweight, fast, and flexible lexical analyzer for tokenizing source code with zero dependencies.\n//\n// repo   : https://github.com/je-es/lexer\n// author : https://github.com/maysara-elshewehy\n//\n// Developed with ❤️ by Maysara.\n\n\n\n// ╔════════════════════════════════════════ PACK ════════════════════════════════════════╗\n\n    import { Lexer, error as customError, compile as customCompile } from './core';\n\n// ╚══════════════════════════════════════════════════════════════════════════════════════╝\n\n\n\n// ╔════════════════════════════════════════ INIT ════════════════════════════════════════╗\n\n    // Token interface\n    export interface Token {\n        type        : string;\n        value       : string | null;\n        pos         : { line: number; col: number; };\n    }\n\n    // Lexer rules type\n    export type Rules = Lexer;\n\n    // Error token symbol\n    export const error = customError;\n\n// ╚══════════════════════════════════════════════════════════════════════════════════════╝\n\n\n\n// ╔════════════════════════════════════════ CORE ════════════════════════════════════════╗\n\n    /**\n     * Creates lexer rules for tokenizing source code.\n     *\n     * @param rules - An object containing lexer rules for different token types.\n     *\n     * @returns A lexer that can tokenize source code.\n     */\n    export const createRules = customCompile;\n\n    /**\n     * Tokenizes the given source code using the provided lexer rules.\n     * Optimized version that pre-allocates token array and avoids unnecessary checks.\n     *\n     * @param rules         - The lexer rules to apply for tokenizing the source code.\n     * @param source_code   - The source code to be tokenized.\n     *\n     * @returns An array of tokens, each with its type, value, and position.\n     */\n    export function tokenize(rules: Rules, source_code: string): Token[] {\n        const sourceLength = source_code.length;\n\n        // Early return for empty input\n        if (sourceLength === 0) {\n            return [];\n        }\n\n        // Use regular array and let JavaScript handle resizing\n        const tokens: Token[] = [];\n\n        rules.reset(source_code);\n\n        // Optimized token iteration - avoid iterator overhead\n        let token = rules.next();\n        while (token !== undefined) {\n            tokens.push({\n                type    : token.type,\n                value   : token.value.length ? token.value : null,\n                pos     : { line: token.line, col: token.col }\n            });\n\n            // Stop on error to match original behavior\n            if (token.type === \"error\") break;\n\n            token = rules.next();\n        }\n\n        return tokens;\n    }\n\n    // Export default object\n    export default { createRules, error, tokenize };\n\n// ╚══════════════════════════════════════════════════════════════════════════════════════╝"],"mappings":";AAkCW,IAAM,QAAN,MAAY;AAAA,EAWf,YAAY,OAAc;AAV1B,SAAQ,YAA0D;AAClE,SAAQ,YAA0D,CAAC;AACnE,SAAQ,iBAA0D,CAAC;AACnE,SAAQ,iBAA0D,CAAC;AACnE,SAAQ,SAA0D;AAClE,SAAQ,WAA0D;AAClE,SAAQ,OAA0D;AAClE,SAAQ,MAA0D;AAClE,SAAQ,SAA0D;AAG9D,SAAK,aAAa,KAAK;AAAA,EAC3B;AAAA,EAEQ,aAAa,OAAoB;AACrC,UAAM,WAAwD,CAAC;AAC/D,UAAM,QAAwD,CAAC;AAC/D,UAAM,aAAwD,CAAC;AAC/D,UAAM,aAAwD,CAAC;AAE/D,eAAW,CAAC,MAAM,IAAI,KAAK,OAAO,QAAQ,KAAK,GAAG;AAC9C,UAAI;AACJ,UAAI,YAAsD;AAC1D,UAAI,gBAAsD;AAE1D,UAAI,OAAO,SAAS,YAAY,SAAS,OAAO;AAE5C;AAAA,MACJ,WAAW,OAAO,SAAS,UAAU;AACjC,kBAAU,KAAK,YAAY,IAAI;AAAA,MACnC,WAAW,gBAAgB,QAAQ;AAC/B,kBAAU,KAAK;AAAA,MACnB,WAAW,MAAM,QAAQ,IAAI,GAAG;AAE5B,YAAI,KAAK,WAAW,GAAG;AACnB,oBAAU,GAAG,KAAK,YAAY,KAAK,CAAC,CAAC,CAAC;AAAA,QAC1C,OAAO;AACH,oBAAU,MAAM,KAAK,IAAI,OAAK,KAAK,YAAY,CAAC,CAAC,EAAE,KAAK,GAAG,CAAC;AAAA,QAChE;AAAA,MACJ,OAAO;AAEH,cAAM,SAAS;AACf,kBAAU,OAAO,MAAM;AACvB,oBAAY,OAAO,SAAS;AAC5B,wBAAgB,OAAO,cAAc;AAAA,MACzC;AAEA,eAAS,KAAK,IAAI,OAAO,GAAG;AAC5B,YAAM,KAAK,IAAI;AACf,iBAAW,KAAK,SAAS;AACzB,iBAAW,KAAK,aAAa;AAAA,IACjC;AAGA,QAAI,SAAS,SAAS,GAAG;AACrB,WAAK,YAAY,IAAI,OAAO,SAAS,KAAK,GAAG,GAAG,IAAI;AAAA,IACxD;AAGA,SAAK,YAAY;AACjB,SAAK,iBAAiB;AACtB,SAAK,iBAAiB;AAAA,EAC1B;AAAA,EAEQ,YAAY,KAAqB;AACrC,WAAO,IAAI,QAAQ,uBAAuB,MAAM;AAAA,EACpD;AAAA,EAEA,MAAM,OAAqB;AACvB,SAAK,SAAS;AACd,SAAK,SAAS,MAAM;AACpB,SAAK,WAAW;AAChB,SAAK,OAAO;AACZ,SAAK,MAAM;AAEX,QAAI,KAAK,WAAW;AAChB,WAAK,UAAU,YAAY;AAAA,IAC/B;AAAA,EACJ;AAAA,EAEA,OAA0B;AAEtB,QAAI,KAAK,YAAY,KAAK,QAAQ;AAC9B,aAAO;AAAA,IACX;AAEA,QAAI,KAAK,WAAW;AAChB,WAAK,UAAU,YAAY,KAAK;AAChC,YAAM,QAAQ,KAAK,UAAU,KAAK,KAAK,MAAM;AAE7C,UAAI,SAAS,MAAM,UAAU,KAAK,UAAU;AAExC,YAAI,YAAY;AAChB,YAAI,OAAO;AAGX,iBAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACnC,cAAI,MAAM,CAAC,MAAM,QAAW;AACxB,wBAAY,IAAI;AAChB,mBAAO,MAAM,CAAC;AACd;AAAA,UACJ;AAAA,QACJ;AAEA,cAAM,YAAY,KAAK;AACvB,cAAM,WAAW,KAAK;AACtB,cAAM,WAAW,KAAK;AACtB,cAAM,aAAa,KAAK;AAGxB,aAAK,YAAY;AAGjB,YAAI,KAAK,eAAe,SAAS,GAAG;AAEhC,mBAAS,IAAI,GAAG,IAAI,YAAY,KAAK;AACjC,gBAAI,KAAK,WAAW,CAAC,MAAM,IAAI;AAC3B,mBAAK;AACL,mBAAK,MAAM;AAAA,YACf,OAAO;AACH,mBAAK;AAAA,YACT;AAAA,UACJ;AAAA,QACJ,OAAO;AACH,eAAK,OAAO;AAAA,QAChB;AAGA,cAAM,YAAY,KAAK,eAAe,SAAS;AAC/C,cAAM,QAAQ,YAAY,UAAU,IAAI,IAAI;AAE5C,eAAO;AAAA,UACH,MAAc,KAAK,UAAU,SAAS;AAAA,UACtC;AAAA,UACA,QAAc;AAAA,UACd,MAAc;AAAA,UACd,KAAc;AAAA,QAClB;AAAA,MACJ;AAAA,IACJ;AAGA,UAAM,OAAO,KAAK,OAAO,KAAK,QAAQ;AACtC,UAAM,QAAQ;AAAA,MACV,MAAc;AAAA,MACd,OAAc;AAAA,MACd,QAAc,KAAK;AAAA,MACnB,MAAc,KAAK;AAAA,MACnB,KAAc,KAAK;AAAA,IACvB;AAEA,SAAK;AACL,SAAK;AAEL,WAAO;AAAA,EACX;AAAA,EAEA,EAAE,OAAO,QAAQ,IAAqB;AAClC,QAAI;AACJ,YAAQ,QAAQ,KAAK,KAAK,OAAO,QAAW;AACxC,YAAM;AAAA,IACV;AAAA,EACJ;AACJ;AAEO,IAAM,QAAQ,OAAO,OAAO;AAE5B,SAAS,QAAQ,OAAqB;AACzC,SAAO,IAAI,MAAM,KAAK;AAC1B;;;AC9KO,IAAMA,SAAQ;AAed,IAAM,cAAc;AAWpB,SAAS,SAAS,OAAc,aAA8B;AACjE,QAAM,eAAe,YAAY;AAGjC,MAAI,iBAAiB,GAAG;AACpB,WAAO,CAAC;AAAA,EACZ;AAGA,QAAM,SAAkB,CAAC;AAEzB,QAAM,MAAM,WAAW;AAGvB,MAAI,QAAQ,MAAM,KAAK;AACvB,SAAO,UAAU,QAAW;AACxB,WAAO,KAAK;AAAA,MACR,MAAU,MAAM;AAAA,MAChB,OAAU,MAAM,MAAM,SAAS,MAAM,QAAQ;AAAA,MAC7C,KAAU,EAAE,MAAM,MAAM,MAAM,KAAK,MAAM,IAAI;AAAA,IACjD,CAAC;AAGD,QAAI,MAAM,SAAS,QAAS;AAE5B,YAAQ,MAAM,KAAK;AAAA,EACvB;AAEA,SAAO;AACX;AAGA,IAAO,gBAAQ,EAAE,aAAa,OAAAA,QAAO,SAAS;","names":["error"]}